#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ•°æ®ä¿æŠ¤ - ç™½åå•æ¨¡å¼ - é˜²é‡å¤å‘Šè­¦
"""

import pymysql
import json
import hashlib
from datetime import datetime
from pathlib import Path
import sys
import os
import subprocess

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from dotenv import load_dotenv

load_dotenv('/opt/mysql-sync/.env')

# å…è®¸ç»“æž„å˜æ›´çš„è¡¨
ALLOWED_SCHEMA_CHANGE_TABLES = {'quota_data', 'tokens', 'users'}
# å…³é”®è¡¨
CRITICAL_TABLES = {'redemptions', 'top_ups'}

def send_alert(message, severity='CRITICAL'):
    """å‘é€é‚®ä»¶å‘Šè­¦"""
    try:
        subprocess.run(
            ['python3', '/opt/mysql-sync/scripts/alert_email.py', message, severity],
            timeout=30, check=False
        )
        print("  ðŸ“§ é‚®ä»¶å‘Šè­¦å·²å‘é€")
    except Exception as e:
        print(f"  âš ï¸  é‚®ä»¶å‘é€å¤±è´¥: {e}")

class SmartDataProtector:
    def __init__(self):
        self.cache_dir = Path('/opt/mysql-sync/cache')
        self.cache_dir.mkdir(exist_ok=True)
        self.baseline_file = self.cache_dir / 'baseline.json'
        self.alert_file = self.cache_dir / 'alerts.json'
        self.pause_file = Path('/opt/mysql-sync/PAUSE_SYNC') # æ–°å¢žï¼šæš‚åœæ–‡ä»¶è·¯å¾„
        self.load_baseline()
        
    def connect_db(self, prefix='MIDDLE'):
        return pymysql.connect(
            host=os.getenv(f'{prefix}_HOST'),
            port=int(os.getenv(f'{prefix}_PORT', 3306)),
            user=os.getenv(f'{prefix}_USER'),
            password=os.getenv(f'{prefix}_PASS'),
            database=os.getenv(f'{prefix}_DB'),
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
    
    def load_baseline(self):
        if self.baseline_file.exists():
            with open(self.baseline_file, 'r') as f:
                self.baseline = json.load(f)
        else:
            self.baseline = {'table_schemas': {}, 'row_counts': {}}
    
    def save_baseline(self):
        self.baseline['last_update'] = datetime.now().isoformat()
        with open(self.baseline_file, 'w') as f:
            json.dump(self.baseline, f, indent=2)

    def create_baseline(self):
         # æ·»åŠ æš‚åœçŠ¶æ€æ£€æŸ¥
        if self.pause_file.exists():
            print("ðŸš« ç³»ç»Ÿå¤„äºŽæš‚åœçŠ¶æ€ï¼Œæ‹’ç»åˆ›å»ºæ–°åŸºçº¿ä»¥é˜²æ­¢æŽ©ç›–æ•°æ®é—®é¢˜ã€‚")
            print("ðŸ’¡ è¯·å…ˆè§£å†³æ•°æ®ä¿æŠ¤å‘Šè­¦ï¼Œç³»ç»Ÿè‡ªåŠ¨æ¢å¤åŽå†é‡æ–°åˆ›å»ºåŸºçº¿ã€‚")
            sys.exit(1)
        
        print("ðŸ“¸ åˆ›å»ºæ•°æ®åŸºçº¿å¿«ç…§...")
        conn = self.connect_db('MIDDLE')
        cursor = conn.cursor()
        cursor.execute("SHOW TABLES")
        tables = [list(row.values())[0] for row in cursor.fetchall()]
        for table in tables:
            if table.startswith('_'): continue
            try:
                cursor.execute(f"SHOW CREATE TABLE `{table}`")
                schema_hash = hashlib.md5(str(cursor.fetchone()).encode()).hexdigest()
                self.baseline['table_schemas'][table] = schema_hash
                cursor.execute(f"SELECT COUNT(*) as cnt FROM `{table}`")
                self.baseline['row_counts'][table] = cursor.fetchone()['cnt']
                print(f"  âœ“ {table}: {self.baseline['row_counts'][table]:,} rows")
            except Exception as e: print(f"  âœ— {table}: {e}")
        cursor.close()
        conn.close()
        self.save_baseline()
        print("\nâœ… åŸºçº¿å·²ä¿å­˜")

    def check_delete_anomaly(self):
        print("\nðŸ” æ£€æŸ¥æ•°æ®åˆ é™¤å¼‚å¸¸...")
        conn = self.connect_db('MIDDLE')
        cursor = conn.cursor()
        alerts = []
        delete_threshold = float(os.getenv('DELETE_THRESHOLD_PERCENT', 10))
        for table, baseline_count in self.baseline.get('row_counts', {}).items():
            try:
                cursor.execute(f"SELECT COUNT(*) as cnt FROM `{table}`")
                current_count = cursor.fetchone()['cnt']
                if baseline_count > 0:
                    decrease_percent = ((baseline_count - current_count) / baseline_count) * 100
                    if decrease_percent > delete_threshold:
                        alerts.append({'type': 'MASSIVE_DELETE', 'severity': 'CRITICAL', 'table': table})
                        print(f"  ðŸš¨ {table}: {baseline_count:,} â†’ {current_count:,} (-{decrease_percent:.1f}%)")
                    else:
                        print(f"  âœ“ {table}: {current_count:,} rows")
            except Exception as e: print(f"  âš ï¸  {table}: {e}")
        cursor.close()
        conn.close()
        return alerts

    def check_schema_change(self):
        print("\nðŸ” æ£€æŸ¥è¡¨ç»“æž„å˜æ›´ï¼ˆæ™ºèƒ½æ¨¡å¼ï¼‰...")
        conn = self.connect_db('MIDDLE')
        cursor = conn.cursor()
        alerts = []
        try:
            cursor.execute("SHOW TABLES")
            current_tables = {list(row.values())[0] for row in cursor.fetchall()}
            baseline_tables = set(self.baseline.get('table_schemas', {}).keys())
            dropped_tables = baseline_tables - current_tables
            if dropped_tables:
                alerts.append({'type': 'TABLE_DROPPED', 'severity': 'CRITICAL', 'tables': list(dropped_tables)})
                print(f"  ðŸš¨ è¡¨è¢«åˆ é™¤: {dropped_tables}")
            
            for table in current_tables:
                if table.startswith('_') or table not in baseline_tables: continue
                cursor.execute(f"SHOW CREATE TABLE `{table}`")
                current_hash = hashlib.md5(str(cursor.fetchone()).encode()).hexdigest()
                baseline_hash = self.baseline['table_schemas'][table]
                if current_hash != baseline_hash:
                    if table in ALLOWED_SCHEMA_CHANGE_TABLES:
                        print(f"  â„¹ï¸  {table}: ç»“æž„å·²å˜æ›´ï¼ˆå…è®¸ï¼Œè‡ªåŠ¨æ›´æ–°ï¼‰")
                        self.baseline['table_schemas'][table] = current_hash
                    elif table in CRITICAL_TABLES:
                        alerts.append({'type': 'CRITICAL_TABLE_SCHEMA_CHANGED', 'severity': 'CRITICAL', 'table': table})
                        print(f"  ðŸš¨ðŸš¨ {table}: å…³é”®è¡¨ç»“æž„è¢«ä¿®æ”¹ï¼")
                    else:
                        alerts.append({'type': 'SCHEMA_CHANGED', 'severity': 'HIGH', 'table': table})
                        print(f"  ðŸš¨ {table}: ç»“æž„å·²å˜æ›´")
                else:
                    print(f"  âœ“ {table}: ç»“æž„æ­£å¸¸")
        except Exception as e: print(f"  âš ï¸  {e}")
        finally:
            cursor.close()
            conn.close()
        return alerts

    def run_full_check(self):
        print("="*70)
        print(f"ðŸ›¡ï¸  æ™ºèƒ½æ•°æ®ä¿æŠ¤æ£€æŸ¥ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*70)
        
        all_alerts = self.check_delete_anomaly() + self.check_schema_change()
        critical_alerts = [a for a in all_alerts if a.get('severity') == 'CRITICAL']
        
        # æ ¸å¿ƒé€»è¾‘ä¿®æ”¹ï¼šå¦‚æžœå·²æš‚åœï¼Œåˆ™ä¸é‡å¤å‘é€å‘Šè­¦
        if self.pause_file.exists() and critical_alerts:
            print("ðŸš« ç³»ç»Ÿå·²æš‚åœï¼Œä¸å†é‡å¤å‘é€å‘Šè­¦ã€‚")
            return False # ä¿æŒæš‚åœçŠ¶æ€

        if critical_alerts:
            print(f"\nðŸš¨ å‘çŽ° {len(critical_alerts)} ä¸ªä¸¥é‡é—®é¢˜ï¼Œæš‚åœåŒæ­¥å¹¶å‘é€å‘Šè­¦ã€‚")
            with open(self.pause_file, 'w') as f:
                report = {'reason': 'Critical data protection alert', 'alerts': critical_alerts}
                json.dump(report, f, indent=2)
            
            alert_msg = f"æ£€æµ‹åˆ° {len(critical_alerts)} ä¸ªä¸¥é‡é—®é¢˜ï¼ŒåŒæ­¥å·²æš‚åœ:\n"
            for alert in critical_alerts:
                alert_msg += f"- {alert['type']}: {alert.get('table', alert.get('tables', 'N/A'))}\n"
            
            send_alert(alert_msg, 'CRITICAL')
            return False
        else:
            print("\nâœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡")
            if self.pause_file.exists():
                self.pause_file.unlink() # å¦‚æžœä¹‹å‰æ˜¯æš‚åœçš„ï¼ŒçŽ°åœ¨é—®é¢˜è§£å†³äº†å°±è‡ªåŠ¨æ¢å¤
                send_alert("âœ… æ•°æ®ä¿æŠ¤é—®é¢˜å·²è§£å†³ï¼ŒåŒæ­¥å·²è‡ªåŠ¨æ¢å¤ã€‚", "INFO")
            self.save_baseline()
            return True

if __name__ == '__main__':
    protector = SmartDataProtector()
    if len(sys.argv) > 1 and sys.argv[1] == 'init':
        protector.create_baseline()
    else:
        result = protector.run_full_check()
        sys.exit(0 if result else 1)
